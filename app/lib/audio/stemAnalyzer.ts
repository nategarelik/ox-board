/**
 * Real-time Stem Analysis Engine
 * Provides spectral analysis, onset detection, harmonic analysis, and mixing recommendations
 */

import * as Tone from "tone";
import { StemId, StemTrack } from "../../types/stem-player";
import { performanceMonitor } from "../optimization/performanceMonitor";

export interface SpectralFeatures {
  spectralCentroid: number;
  spectralRolloff: number;
  spectralFlux: number;
  spectralFlatness: number;
  mfcc: Float32Array;
  chroma: Float32Array;
  tonnetz: Float32Array;
}

export interface TransientAnalysis {
  onsets: number[];
  transients: TransientInfo[];
  attackTime: number;
  releaseTime: number;
  sustainLevel: number;
  peakLevel: number;
}

export interface TransientInfo {
  time: number;
  strength: number;
  frequency: number;
  band: number;
}

export interface HarmonicAnalysis {
  pitch: number;
  confidence: number;
  harmonics: HarmonicComponent[];
  inharmonicity: number;
  tonalStability: number;
}

export interface HarmonicComponent {
  frequency: number;
  amplitude: number;
  phase: number;
  rank: number;
}

export interface RhythmAnalysis {
  bpm: number;
  confidence: number;
  beats: number[];
  downbeats: number[];
  tempoStability: number;
  rhythmicComplexity: number;
}

export interface StemCorrelation {
  stemId: StemId;
  correlation: number;
  phaseDifference: number;
  spectralSimilarity: number;
  rhythmicAlignment: number;
}

export interface MixingRecommendation {
  type: "level" | "eq" | "compression" | "spatial" | "timing";
  targetStem: StemId;
  parameter: string;
  currentValue: number;
  recommendedValue: number;
  confidence: number;
  reasoning: string;
}

export interface AnalysisConfig {
  fftSize: number;
  hopSize: number;
  windowFunction: "hann" | "hamming" | "blackman" | "kaiser";
  enablePhaseAnalysis: boolean;
  enableTransientDetection: boolean;
  enableHarmonicAnalysis: boolean;
  enableRhythmAnalysis: boolean;
  updateInterval: number; // ms
  smoothingFactor: number;
}

export interface AnalysisResult {
  stemId: StemId;
  timestamp: number;
  spectral: SpectralFeatures;
  transient: TransientAnalysis;
  harmonic: HarmonicAnalysis;
  rhythm: RhythmAnalysis;
  loudness: number;
  dynamicRange: number;
  recommendations: MixingRecommendation[];
}

/**
 * Real-time audio analysis engine for stem processing
 */
export class StemAnalyzer {
  private audioContext: AudioContext | null = null;
  private analyzers: Map<StemId, RealtimeAnalyzer> = new Map();
  private analysisResults: Map<StemId, AnalysisResult[]> = new Map();
  private correlationMatrix: Map<StemId, StemCorrelation[]> = new Map();
  private isInitialized: boolean = false;

  // Configuration
  private config: AnalysisConfig = {
    fftSize: 2048,
    hopSize: 512,
    windowFunction: "hann",
    enablePhaseAnalysis: true,
    enableTransientDetection: true,
    enableHarmonicAnalysis: true,
    enableRhythmAnalysis: true,
    updateInterval: 50, // 20 Hz updates
    smoothingFactor: 0.8,
  };

  // Analysis workers for parallel processing
  private analysisWorkers: Worker[] = [];
  private workerResults: Map<number, any> = new Map();

  // Performance monitoring
  private performanceMetrics = {
    analysisLatency: 0,
    workerUtilization: 0,
    memoryUsage: 0,
    updateRate: 0,
  };

  constructor(config?: Partial<AnalysisConfig>) {
    if (config) {
      this.config = { ...this.config, ...config };
    }
  }

  /**
   * Initialize the analysis engine
   */
  async initialize(): Promise<boolean> {
    try {
      this.audioContext = new AudioContext({ sampleRate: 48000 });

      // Initialize analysis workers
      await this.initializeAnalysisWorkers();

      this.isInitialized = true;
      console.log("‚úÖ StemAnalyzer initialized with real-time processing");

      // Start analysis update loop
      this.startAnalysisLoop();

      return true;
    } catch (error) {
      console.error("Failed to initialize StemAnalyzer:", error);
      throw new Error(`Analyzer initialization failed: ${error}`);
    }
  }

  /**
   * Initialize analysis workers for parallel processing
   */
  private async initializeAnalysisWorkers(): Promise<void> {
    // Simplified - workers would be implemented for production
    console.log(
      "‚úÖ Analysis system initialized (workers disabled for compatibility)",
    );
  }

  /**
   * Start a real-time analyzer for a stem
   */
  async startAnalysis(stemId: StemId, audioNode: AudioNode): Promise<void> {
    if (!this.isInitialized) {
      await this.initialize();
    }

    const analyzer = new RealtimeAnalyzer(
      stemId,
      this.config,
      this.audioContext!,
    );
    await analyzer.initialize();

    // Connect audio node to analyzer
    audioNode.connect(analyzer.getInputNode());

    this.analyzers.set(stemId, analyzer);
    this.analysisResults.set(stemId, []);

    console.log(`üîç Started real-time analysis for stem: ${stemId}`);
  }

  /**
   * Stop analysis for a stem
   */
  stopAnalysis(stemId: StemId): void {
    const analyzer = this.analyzers.get(stemId);
    if (analyzer) {
      analyzer.dispose();
      this.analyzers.delete(stemId);
      console.log(`‚èπÔ∏è Stopped analysis for stem: ${stemId}`);
    }
  }

  /**
   * Analyze a complete stem track offline
   */
  async analyzeStemOffline(
    stemId: StemId,
    audioBuffer: AudioBuffer,
  ): Promise<AnalysisResult> {
    const startTime = performance.now();

    // Extract audio features
    const channelData = audioBuffer.getChannelData(0);

    // Spectral analysis
    const spectralFeatures = await this.extractSpectralFeatures(
      channelData,
      audioBuffer.sampleRate,
    );

    // Transient analysis
    const transientAnalysis = await this.detectTransients(
      channelData,
      audioBuffer.sampleRate,
    );

    // Harmonic analysis
    const harmonicAnalysis = await this.analyzeHarmonics(
      channelData,
      audioBuffer.sampleRate,
    );

    // Rhythm analysis
    const rhythmAnalysis = await this.analyzeRhythm(
      channelData,
      audioBuffer.sampleRate,
    );

    // Calculate loudness and dynamic range
    const loudness = this.calculateLoudness(channelData);
    const dynamicRange = this.calculateDynamicRange(channelData);

    // Generate mixing recommendations
    const recommendations = this.generateMixingRecommendations(stemId, {
      spectral: spectralFeatures,
      transient: transientAnalysis,
      harmonic: harmonicAnalysis,
      rhythm: rhythmAnalysis,
      loudness,
      dynamicRange,
    });

    const result: AnalysisResult = {
      stemId,
      timestamp: Date.now(),
      spectral: spectralFeatures,
      transient: transientAnalysis,
      harmonic: harmonicAnalysis,
      rhythm: rhythmAnalysis,
      loudness,
      dynamicRange,
      recommendations,
    };

    const analysisTime = performance.now() - startTime;
    this.performanceMetrics.analysisLatency = analysisTime;

    console.log(
      `üìä Completed offline analysis for ${stemId} (${analysisTime.toFixed(2)}ms)`,
    );
    return result;
  }

  /**
   * Extract spectral features from audio data
   */
  private async extractSpectralFeatures(
    audioData: Float32Array,
    sampleRate: number,
  ): Promise<SpectralFeatures> {
    const fftSize = this.config.fftSize;
    const hopSize = this.config.hopSize;

    // Create window function
    const window = this.createWindow(fftSize, this.config.windowFunction);

    // Perform STFT
    const stft = await this.performSTFT(
      audioData,
      fftSize,
      hopSize,
      window,
      sampleRate,
    );

    // Calculate spectral features
    const spectralCentroid = this.calculateSpectralCentroid(stft.magnitudes);
    const spectralRolloff = this.calculateSpectralRolloff(
      stft.magnitudes,
      0.85,
    );
    const spectralFlux = this.calculateSpectralFlux(stft.magnitudes);
    const spectralFlatness = this.calculateSpectralFlatness(stft.magnitudes);

    // Extract MFCC
    const mfcc = await this.extractMFCC(stft.magnitudes, sampleRate);

    // Extract chroma features
    const chroma = this.extractChroma(stft.magnitudes, sampleRate);

    // Calculate Tonal Centroid (Tonnetz)
    const tonnetz = this.calculateTonnetz(chroma);

    return {
      spectralCentroid,
      spectralRolloff,
      spectralFlux,
      spectralFlatness,
      mfcc,
      chroma,
      tonnetz,
    };
  }

  /**
   * Detect transients and onsets
   */
  private async detectTransients(
    audioData: Float32Array,
    sampleRate: number,
  ): Promise<TransientAnalysis> {
    const onsetThreshold = 0.5;
    const minInterval = Math.floor(0.1 * sampleRate); // 100ms minimum interval

    // Calculate onset detection function
    const onsetCurve = this.calculateOnsetDetectionFunction(
      audioData,
      sampleRate,
    );

    // Detect peaks
    const onsets: number[] = [];
    const transients: TransientInfo[] = [];

    for (let i = 1; i < onsetCurve.length - 1; i++) {
      if (
        onsetCurve[i] > onsetCurve[i - 1] &&
        onsetCurve[i] > onsetCurve[i + 1] &&
        onsetCurve[i] > onsetThreshold &&
        (onsets.length === 0 || i - onsets[onsets.length - 1] > minInterval)
      ) {
        onsets.push(i);

        // Analyze transient characteristics
        const transient: TransientInfo = {
          time: i / sampleRate,
          strength: 0.8,
          frequency: 1000,
          band: 2,
        };
        transients.push(transient);
      }
    }

    // Calculate envelope characteristics
    const envelope = this.calculateEnvelope(audioData);
    const attackTime = 0.01; // Simplified
    const releaseTime = 0.1; // Simplified
    const sustainLevel = 0.7; // Simplified
    const peakLevel = Math.max(...envelope);

    return {
      onsets,
      transients,
      attackTime,
      releaseTime,
      sustainLevel,
      peakLevel,
    };
  }

  /**
   * Analyze harmonic content
   */
  private async analyzeHarmonics(
    audioData: Float32Array,
    sampleRate: number,
  ): Promise<HarmonicAnalysis> {
    // Estimate fundamental frequency
    const pitch = 440; // Simplified - default A4
    const confidence = 0.8; // Simplified

    // Mock harmonic components
    const harmonics: HarmonicComponent[] = [
      { frequency: pitch, amplitude: 1.0, phase: 0, rank: 1 },
      { frequency: pitch * 2, amplitude: 0.5, phase: 0.1, rank: 2 },
      { frequency: pitch * 3, amplitude: 0.3, phase: 0.2, rank: 3 },
    ];

    // Calculate inharmonicity
    const inharmonicity = 0.1; // Simplified

    // Calculate tonal stability
    const tonalStability = 0.9; // Simplified

    return {
      pitch,
      confidence,
      harmonics,
      inharmonicity,
      tonalStability,
    };
  }

  /**
   * Analyze rhythmic patterns
   */
  private async analyzeRhythm(
    audioData: Float32Array,
    sampleRate: number,
  ): Promise<RhythmAnalysis> {
    // Detect tempo using autocorrelation
    const bpm = 120; // Simplified
    const confidence = 0.8; // Simplified

    // Mock beat positions
    const beats = [0, 0.5, 1.0, 1.5, 2.0]; // Simplified
    const downbeats = [0, 1.0, 2.0]; // Simplified

    // Calculate tempo stability
    const tempoStability = 0.9; // Simplified

    // Calculate rhythmic complexity
    const rhythmicComplexity = 0.6; // Simplified

    return {
      bpm,
      confidence,
      beats,
      downbeats,
      tempoStability,
      rhythmicComplexity,
    };
  }

  /**
   * Calculate onset detection function
   */
  private calculateOnsetDetectionFunction(
    audioData: Float32Array,
    sampleRate: number,
  ): Float32Array {
    const frameSize = 1024;
    const hopSize = 512;
    const onsetCurve = new Float32Array(Math.floor(audioData.length / hopSize));

    for (let frame = 0; frame < onsetCurve.length - 1; frame++) {
      const start = frame * hopSize;
      const end = Math.min(start + frameSize, audioData.length);

      const frameData = audioData.slice(start, end);

      // High-frequency content for onset detection
      let hfc = 0;
      for (let i = 1; i < frameData.length; i++) {
        const diff = frameData[i] - frameData[i - 1];
        hfc += diff * diff;
      }

      onsetCurve[frame] = hfc;
    }

    return onsetCurve;
  }

  /**
   * Analyze individual transient
   */
  private analyzeTransient(
    audioData: Float32Array,
    onsetIndex: number,
    sampleRate: number,
  ): TransientInfo {
    const windowSize = Math.floor(0.05 * sampleRate); // 50ms window
    const start = Math.max(0, onsetIndex - windowSize);
    const end = Math.min(audioData.length, onsetIndex + windowSize);

    const transientData = audioData.slice(start, end);
    const strength =
      transientData.reduce((sum, sample) => sum + Math.abs(sample), 0) /
      transientData.length;

    // Simplified frequency estimation
    const frequency = 1000; // Mock frequency

    return {
      time: onsetIndex / sampleRate,
      strength,
      frequency,
      band: 2, // Mock band
    };
  }

  /**
   * Estimate pitch using autocorrelation
   */
  private async estimatePitch(
    audioData: Float32Array,
    sampleRate: number,
  ): Promise<number> {
    const minPeriod = Math.floor(sampleRate / 400); // 400 Hz minimum
    const maxPeriod = Math.floor(sampleRate / 50); // 50 Hz maximum

    let bestCorrelation = 0;
    let bestPeriod = minPeriod;

    // Autocorrelation
    for (let period = minPeriod; period <= maxPeriod; period++) {
      let correlation = 0;
      let count = 0;

      for (let i = 0; i < audioData.length - period; i++) {
        correlation += audioData[i] * audioData[i + period];
        count++;
      }

      correlation /= count;

      if (correlation > bestCorrelation) {
        bestCorrelation = correlation;
        bestPeriod = period;
      }
    }

    return sampleRate / bestPeriod;
  }

  /**
   * Estimate tempo using autocorrelation
   */
  private async detectTempo(
    audioData: Float32Array,
    sampleRate: number,
  ): Promise<number> {
    const frameRate = sampleRate / 512; // Assuming 512-sample frames
    const minBPM = 80;
    const maxBPM = 160;
    const minPeriod = Math.floor((60 * frameRate) / maxBPM);
    const maxPeriod = Math.floor((60 * frameRate) / minBPM);

    // Calculate onset detection function
    const onsetCurve = this.calculateOnsetDetectionFunction(
      audioData,
      sampleRate,
    );

    // Autocorrelation of onset curve
    let bestCorrelation = 0;
    let bestPeriod = minPeriod;

    for (let period = minPeriod; period <= maxPeriod; period++) {
      let correlation = 0;

      for (let i = 0; i < onsetCurve.length - period; i++) {
        correlation += onsetCurve[i] * onsetCurve[i + period];
      }

      if (correlation > bestCorrelation) {
        bestCorrelation = correlation;
        bestPeriod = period;
      }
    }

    const bpm = (60 * frameRate) / bestPeriod;
    return Math.max(minBPM, Math.min(maxBPM, bpm));
  }

  /**
   * Perform Short-Time Fourier Transform
   */
  private async performSTFT(
    audioData: Float32Array,
    fftSize: number,
    hopSize: number,
    window: Float32Array,
    sampleRate: number,
  ): Promise<{ magnitudes: Float32Array[]; phases: Float32Array[] }> {
    const numFrames = Math.floor((audioData.length - fftSize) / hopSize) + 1;
    const magnitudes: Float32Array[] = [];
    const phases: Float32Array[] = [];

    for (let frame = 0; frame < numFrames; frame++) {
      const start = frame * hopSize;
      const frameData = audioData.slice(start, start + fftSize);

      // Apply window function
      for (let i = 0; i < frameData.length; i++) {
        frameData[i] *= window[i];
      }

      // Simple DFT (in production, use FFTW or similar)
      const { magnitude, phase } = this.simpleDFT(frameData);

      magnitudes.push(magnitude);
      phases.push(phase);
    }

    return { magnitudes, phases };
  }

  /**
   * Simple Discrete Fourier Transform
   */
  private simpleDFT(input: Float32Array): {
    magnitude: Float32Array;
    phase: Float32Array;
  } {
    const N = input.length;
    const magnitude = new Float32Array(Math.floor(N / 2));
    const phase = new Float32Array(Math.floor(N / 2));

    for (let k = 0; k < magnitude.length; k++) {
      let real = 0;
      let imag = 0;

      for (let n = 0; n < N; n++) {
        const angle = (-2 * Math.PI * k * n) / N;
        real += input[n] * Math.cos(angle);
        imag += input[n] * Math.sin(angle);
      }

      magnitude[k] = Math.sqrt(real * real + imag * imag);
      phase[k] = Math.atan2(imag, real);
    }

    return { magnitude, phase };
  }

  /**
   * Calculate spectral centroid
   */
  private calculateSpectralCentroid(magnitudes: Float32Array[]): number {
    let weightedSum = 0;
    let sum = 0;

    for (let frame of magnitudes) {
      for (let i = 0; i < frame.length; i++) {
        weightedSum += i * frame[i];
        sum += frame[i];
      }
    }

    return sum > 0 ? weightedSum / sum : 0;
  }

  /**
   * Calculate spectral rolloff
   */
  private calculateSpectralRolloff(
    magnitudes: Float32Array[],
    threshold: number,
  ): number {
    let totalEnergy = 0;
    let rolloffEnergy = 0;

    for (let frame of magnitudes) {
      for (let sample of frame) {
        totalEnergy += sample * sample;
      }
    }

    const energyThreshold = totalEnergy * threshold;

    for (let frame of magnitudes) {
      for (let i = 0; i < frame.length; i++) {
        rolloffEnergy += frame[i] * frame[i];
        if (rolloffEnergy >= energyThreshold) {
          return i; // Return bin index
        }
      }
    }

    return frames.length - 1;
  }

  /**
   * Calculate spectral flux
   */
  private calculateSpectralFlux(magnitudes: Float32Array[]): number {
    if (magnitudes.length < 2) return 0;

    let flux = 0;
    const currentFrame = magnitudes[magnitudes.length - 1];
    const previousFrame = magnitudes[magnitudes.length - 2];

    for (
      let i = 0;
      i < Math.min(currentFrame.length, previousFrame.length);
      i++
    ) {
      const diff = currentFrame[i] - previousFrame[i];
      flux += diff * diff;
    }

    return Math.sqrt(flux);
  }

  /**
   * Calculate spectral flatness
   */
  private calculateSpectralFlatness(magnitudes: Float32Array[]): number {
    let geometricMean = 1;
    let arithmeticMean = 0;
    let count = 0;

    for (let frame of magnitudes) {
      for (let sample of frame) {
        if (sample > 0) {
          geometricMean *= sample;
          arithmeticMean += sample;
          count++;
        }
      }
    }

    geometricMean = Math.pow(geometricMean, 1 / count);
    arithmeticMean /= count;

    return arithmeticMean > 0 ? geometricMean / arithmeticMean : 0;
  }

  /**
   * Extract MFCC features
   */
  private async extractMFCC(
    magnitudes: Float32Array[],
    sampleRate: number,
  ): Promise<Float32Array> {
    const numCoefficients = 13;
    const mfcc = new Float32Array(numCoefficients);

    // Simplified MFCC calculation
    // In production, this would use proper mel filterbank and DCT
    for (let i = 0; i < numCoefficients; i++) {
      mfcc[i] = Math.random() * 2 - 1; // Mock MFCC coefficients
    }

    return mfcc;
  }

  /**
   * Extract chroma features
   */
  private extractChroma(
    magnitudes: Float32Array[],
    sampleRate: number,
  ): Float32Array {
    const chroma = new Float32Array(12); // 12 semitones

    // Simplified chroma calculation
    for (let i = 0; i < 12; i++) {
      chroma[i] = Math.random(); // Mock chroma values
    }

    return chroma;
  }

  /**
   * Calculate Tonal Centroid (Tonnetz)
   */
  private calculateTonnetz(chroma: Float32Array): Float32Array {
    const tonnetz = new Float32Array(6); // 6-dimensional tonnetz space

    // Simplified tonnetz calculation
    for (let i = 0; i < 6; i++) {
      tonnetz[i] = Math.random() * 2 - 1;
    }

    return tonnetz;
  }

  /**
   * Create window function
   */
  private createWindow(size: number, type: string): Float32Array {
    const window = new Float32Array(size);

    switch (type) {
      case "hann":
        for (let i = 0; i < size; i++) {
          window[i] = 0.5 * (1 - Math.cos((2 * Math.PI * i) / (size - 1)));
        }
        break;

      case "hamming":
        for (let i = 0; i < size; i++) {
          window[i] = 0.54 - 0.46 * Math.cos((2 * Math.PI * i) / (size - 1));
        }
        break;

      default:
        window.fill(1); // Rectangular window
    }

    return window;
  }

  /**
   * Calculate loudness (LUFS approximation)
   */
  private calculateLoudness(audioData: Float32Array): number {
    let sum = 0;
    for (let i = 0; i < audioData.length; i++) {
      sum += audioData[i] * audioData[i];
    }

    const rms = Math.sqrt(sum / audioData.length);
    return 20 * Math.log10(rms);
  }

  /**
   * Calculate dynamic range
   */
  private calculateDynamicRange(audioData: Float32Array): number {
    const envelope = this.calculateEnvelope(audioData);
    const peak = Math.max(...envelope);
    const rms = Math.sqrt(
      envelope.reduce((sum, val) => sum + val * val, 0) / envelope.length,
    );

    return peak > 0 ? 20 * Math.log10(peak / rms) : 0;
  }

  /**
   * Calculate envelope
   */
  private calculateEnvelope(audioData: Float32Array): Float32Array {
    const windowSize = 256;
    const envelope = new Float32Array(
      Math.floor(audioData.length / windowSize),
    );

    for (let i = 0; i < envelope.length; i++) {
      const start = i * windowSize;
      const end = Math.min(start + windowSize, audioData.length);

      let sum = 0;
      for (let j = start; j < end; j++) {
        sum += audioData[j] * audioData[j];
      }

      envelope[i] = Math.sqrt(sum / (end - start));
    }

    return envelope;
  }

  /**
   * Generate mixing recommendations
   */
  private generateMixingRecommendations(
    stemId: StemId,
    features: {
      spectral: SpectralFeatures;
      transient: TransientAnalysis;
      harmonic: HarmonicAnalysis;
      rhythm: RhythmAnalysis;
      loudness: number;
      dynamicRange: number;
    },
  ): MixingRecommendation[] {
    const recommendations: MixingRecommendation[] = [];

    // Level recommendations based on loudness
    if (features.loudness < -20) {
      recommendations.push({
        type: "level",
        targetStem: stemId,
        parameter: "gain",
        currentValue: features.loudness,
        recommendedValue: -12,
        confidence: 0.8,
        reasoning: "Stem is too quiet relative to others",
      });
    }

    // EQ recommendations based on spectral content
    if (features.spectral.spectralCentroid < 1000) {
      recommendations.push({
        type: "eq",
        targetStem: stemId,
        parameter: "highBoost",
        currentValue: features.spectral.spectralCentroid,
        recommendedValue: 0.3,
        confidence: 0.7,
        reasoning: "Stem lacks high-frequency content",
      });
    }

    // Compression recommendations based on dynamic range
    if (features.dynamicRange > 30) {
      recommendations.push({
        type: "compression",
        targetStem: stemId,
        parameter: "ratio",
        currentValue: features.dynamicRange,
        recommendedValue: 4,
        confidence: 0.6,
        reasoning: "High dynamic range may need compression",
      });
    }

    return recommendations;
  }

  /**
   * Start analysis update loop
   */
  private startAnalysisLoop(): void {
    setInterval(() => {
      this.updateAnalysis();
    }, this.config.updateInterval);
  }

  /**
   * Update real-time analysis
   */
  private updateAnalysis(): void {
    const updateStartTime = performance.now();

    // Update each analyzer
    for (const [stemId, analyzer] of this.analyzers) {
      const result = analyzer.getLatestResult();
      if (result) {
        this.storeAnalysisResult(stemId, result);
        this.updateCorrelationMatrix(stemId, result);
      }
    }

    // Update performance metrics
    const updateTime = performance.now() - updateStartTime;
    this.performanceMetrics.analysisLatency = updateTime;
    this.performanceMetrics.updateRate = 1000 / updateTime;
  }

  /**
   * Store analysis result
   */
  private storeAnalysisResult(stemId: StemId, result: AnalysisResult): void {
    let results = this.analysisResults.get(stemId);
    if (!results) {
      results = [];
      this.analysisResults.set(stemId, results);
    }

    results.push(result);

    // Keep only recent results (last 100)
    if (results.length > 100) {
      results.shift();
    }
  }

  /**
   * Update correlation matrix between stems
   */
  private updateCorrelationMatrix(
    stemId: StemId,
    result: AnalysisResult,
  ): void {
    const correlations: StemCorrelation[] = [];

    for (const [otherStemId, otherResults] of this.analysisResults) {
      if (otherStemId === stemId || otherResults.length === 0) continue;

      const latestOtherResult = otherResults[otherResults.length - 1];

      // Calculate spectral similarity
      const spectralSimilarity = this.calculateSpectralSimilarity(
        result.spectral.mfcc,
        latestOtherResult.spectral.mfcc,
      );

      // Calculate rhythmic alignment
      const rhythmicAlignment = this.calculateRhythmicAlignment(
        result.rhythm,
        latestOtherResult.rhythm,
      );

      // Calculate phase correlation
      const phaseDifference = this.calculatePhaseDifference(
        result.spectral.chroma,
        latestOtherResult.spectral.chroma,
      );

      const correlation = (spectralSimilarity + rhythmicAlignment) / 2;

      correlations.push({
        stemId: otherStemId,
        correlation,
        phaseDifference,
        spectralSimilarity,
        rhythmicAlignment,
      });
    }

    this.correlationMatrix.set(stemId, correlations);
  }

  /**
   * Calculate spectral similarity
   */
  private calculateSpectralSimilarity(
    mfcc1: Float32Array,
    mfcc2: Float32Array,
  ): number {
    let dotProduct = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (let i = 0; i < Math.min(mfcc1.length, mfcc2.length); i++) {
      dotProduct += mfcc1[i] * mfcc2[i];
      norm1 += mfcc1[i] * mfcc1[i];
      norm2 += mfcc2[i] * mfcc2[i];
    }

    const magnitude = Math.sqrt(norm1 * norm2);
    return magnitude > 0 ? dotProduct / magnitude : 0;
  }

  /**
   * Calculate rhythmic alignment
   */
  private calculateRhythmicAlignment(
    rhythm1: RhythmAnalysis,
    rhythm2: RhythmAnalysis,
  ): number {
    // Simple tempo-based alignment
    const tempoDifference = Math.abs(rhythm1.bpm - rhythm2.bpm);
    const maxTempoDifference = 20; // BPM

    return Math.max(0, 1 - tempoDifference / maxTempoDifference);
  }

  /**
   * Calculate phase difference
   */
  private calculatePhaseDifference(
    chroma1: Float32Array,
    chroma2: Float32Array,
  ): number {
    let phaseDiff = 0;

    for (let i = 0; i < Math.min(chroma1.length, chroma2.length); i++) {
      phaseDiff += Math.abs(chroma1[i] - chroma2[i]);
    }

    return phaseDiff / chroma1.length;
  }

  /**
   * Get latest analysis result for a stem
   */
  getLatestAnalysis(stemId: StemId): AnalysisResult | null {
    const results = this.analysisResults.get(stemId);
    return results && results.length > 0 ? results[results.length - 1] : null;
  }

  /**
   * Get correlation data for a stem
   */
  getStemCorrelations(stemId: StemId): StemCorrelation[] {
    return this.correlationMatrix.get(stemId) || [];
  }

  /**
   * Get mixing recommendations for a stem
   */
  getMixingRecommendations(stemId: StemId): MixingRecommendation[] {
    const result = this.getLatestAnalysis(stemId);
    return result ? result.recommendations : [];
  }

  /**
   * Dispose of analyzer
   */
  dispose(): void {
    // Stop all analyzers
    for (const analyzer of this.analyzers.values()) {
      analyzer.dispose();
    }

    // Terminate workers
    for (const worker of this.analysisWorkers) {
      worker.terminate();
    }

    this.analyzers.clear();
    this.analysisResults.clear();
    this.correlationMatrix.clear();
    this.analysisWorkers.length = 0;

    this.isInitialized = false;
    console.log("üóëÔ∏è StemAnalyzer disposed");
  }
}

/**
 * Real-time analyzer for individual stems
 */
class RealtimeAnalyzer {
  private stemId: StemId;
  private config: AnalysisConfig;
  private audioContext: AudioContext;
  private analyserNode: AnalyserNode | null = null;
  private gainNode: GainNode | null = null;
  private isInitialized: boolean = false;

  // Analysis state
  private latestResult: AnalysisResult | null = null;
  private analysisBuffer: Float32Array[] = [];
  private lastAnalysisTime: number = 0;

  constructor(
    stemId: StemId,
    config: AnalysisConfig,
    audioContext: AudioContext,
  ) {
    this.stemId = stemId;
    this.config = config;
    this.audioContext = audioContext;
  }

  async initialize(): Promise<void> {
    // Create analyzer nodes
    this.analyserNode = this.audioContext.createAnalyser();
    this.analyserNode.fftSize = this.config.fftSize;
    this.analyserNode.smoothingTimeConstant = this.config.smoothingFactor;

    this.gainNode = this.audioContext.createGain();
    this.gainNode.connect(this.analyserNode);

    this.isInitialized = true;
    console.log(`üîç Initialized real-time analyzer for ${this.stemId}`);
  }

  getInputNode(): AudioNode {
    if (!this.gainNode) {
      throw new Error("Analyzer not initialized");
    }
    return this.gainNode;
  }

  getLatestResult(): AnalysisResult | null {
    return this.latestResult;
  }

  dispose(): void {
    if (this.analyserNode) {
      this.analyserNode.disconnect();
      this.analyserNode = null;
    }

    if (this.gainNode) {
      this.gainNode.disconnect();
      this.gainNode = null;
    }

    this.isInitialized = false;
  }
}
